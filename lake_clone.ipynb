{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/miniconda3/envs/zcar01/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/gpu:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import datetime\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D, Cropping2D, Dropout, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "#TensorFlowがGPUを認識しているか確認\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "raw_driving_log_name = \"driving_log.csv\"\n",
    "\n",
    "raw_driving_log_path = data_dir + raw_driving_log_name\n",
    "driving_log_name = \"driving_log2.csv\"\n",
    "driving_file_path = data_dir + driving_log_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driving_logファイルのPATHを修正\n",
    "def convert2filepath(local_path):\n",
    "    start_index = local_path.find(\"IMG\")\n",
    "    converted_path = data_dir + local_path[start_index::]\n",
    "    return converted_path\n",
    "\n",
    "df = pd.read_csv(raw_driving_log_path, header=None, names=('center_path', 'left_path', 'right_path', \"degree\", \"throttle\", \"brake\", \"speed\"))\n",
    "df[\"center_path\"] = df[\"center_path\"].map(convert2filepath)\n",
    "df[\"left_path\"] = df[\"left_path\"].map(convert2filepath)\n",
    "df[\"right_path\"] = df[\"right_path\"].map(convert2filepath)\n",
    "df.to_csv(driving_file_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrowsFromDrivingLogs(dataPath):\n",
    "    rows = []\n",
    "    with open(dataPath + \"/\" + driving_log_name) as csvFile:\n",
    "        reader = csv.reader(csvFile)            \n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def getImageArray3angle(imagePath, steering, images, steerings):\n",
    "    originalImage = cv2.imread(imagePath.strip())\n",
    "    image = cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB)\n",
    "    images.append(image)\n",
    "    steerings.append(steering)\n",
    "\n",
    "def getReverseImageArray3angle(imagePath, steering, images, steerings):\n",
    "    originalImage = cv2.imread(imagePath.strip())\n",
    "    image = cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB)\n",
    "    reversed_image = cv2.flip(image,1)\n",
    "    steering_flipped = - steering # ステアリング角度が左折状態になっているので、左右逆転させることで右折にします。\n",
    "\n",
    "    images.append(reversed_image)\n",
    "    steerings.append(steering_flipped) \n",
    "    \n",
    "def getImagesAndSteerings(rows):\n",
    "    \n",
    "    images = []\n",
    "    steerings = []\n",
    "    \n",
    "    for row in rows:\n",
    "        #角度\n",
    "        steering = float(row[3])\n",
    "        # 左右のカメラのステアリング測定値を調整します\n",
    "        parameter = 0.2 \n",
    "        # このパラメータが調整用の値です。\n",
    "        # 左のカメラはステアリング角度が実際よりも低めに記録されているので、少し値を足してやります。右のカメラはその逆です。\n",
    "        steering_left = steering + parameter\n",
    "        steering_right = steering - parameter\n",
    "\n",
    "        getImageArray3angle(row[0], steering, images, steerings)\n",
    "        getImageArray3angle(row[1], steering_left, images, steerings)\n",
    "        getImageArray3angle(row[2], steering_right, images, steerings)\n",
    "        getReverseImageArray3angle(row[0], steering, images, steerings)\n",
    "        getReverseImageArray3angle(row[1], steering_left, images, steerings)\n",
    "        getReverseImageArray3angle(row[2], steering_right, images, steerings)\n",
    "\n",
    "    return (np.array(images), np.array(steerings))\n",
    "\n",
    "def trainModelAndSave(model, train_data, validation_data, epochs, batch_size):\n",
    "    # 学習パラメータ\n",
    "    loss = 'mean_squared_error'\n",
    "    learn_rate = 1.0e-4\n",
    "    optimizer = RMSprop(learn_rate)\n",
    "    now = datetime.datetime.now()\n",
    "    filename = now.strftime('%Y%m%d_%H%M%S') \n",
    "\n",
    "    # compile and train the model using the generator function\n",
    "    train_size = len(train_data)*2*3\n",
    "    valid_size = len(validation_data)*2*3\n",
    "\n",
    "    file_path_model = filename + \"_model-weights.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(file_path_model, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')  \n",
    "    callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "    #モデルの設定\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    #モデルの学習\n",
    "    history_object = model.fit_generator(batch_generator(train_data, batch_size=batch_size),\n",
    "                                         samples_per_epoch=train_size,\n",
    "                                         validation_data=batch_generator(validation_data, batch_size=batch_size), \n",
    "                                         nb_val_samples=valid_size, nb_epoch=epochs, verbose=1,\n",
    "                                         callbacks = callbacks_list)\n",
    "    #モデルの保存\n",
    "    model.save(filename + '_model.h5')\n",
    "    return history_object\n",
    "\n",
    "def loadCSVData():\n",
    "    data = []\n",
    "    with open(driving_file_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            data.append(line)\n",
    "            \n",
    "    train_data, validation_data = train_test_split(data, test_size=0.2, random_state=0)\n",
    "    return train_data, validation_data\n",
    "\n",
    "def batch_generator(input_data, batch_size):\n",
    "    # ジェネレータが停止しないようにループさせる\n",
    "    while True: \n",
    "        for offset in range(0, len(input_data), batch_size):\n",
    "            batch_data = input_data[offset:offset+batch_size]\n",
    "            images = []\n",
    "            steerings = []\n",
    "\n",
    "            images, steerings = getImagesAndSteerings(batch_data)\n",
    "            yield np.array(images), np.array(steerings)\n",
    "\n",
    "#NVIDIA\n",
    "def nvidia_model():\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((50,20), (1,1)), input_shape=(160,320,3)))\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "    model.add(Conv2D(24,5,5, subsample=(2,2), activation='elu'))\n",
    "    model.add(Conv2D(36,5,5, subsample=(2,2), activation='elu'))\n",
    "    model.add(Conv2D(48,5,5, subsample=(2,2), activation='elu'))\n",
    "    model.add(Conv2D(64,3,3, activation='elu'))\n",
    "    model.add(Conv2D(64,3,3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 2165\n",
      "Training label: 542\n",
      "Epoch 1/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0769Epoch 00000: val_loss improved from inf to 0.07706, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 246s - loss: 0.0770 - val_loss: 0.0771\n",
      "Epoch 2/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0714Epoch 00001: val_loss improved from 0.07706 to 0.07267, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 148s - loss: 0.0715 - val_loss: 0.0727\n",
      "Epoch 3/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0687Epoch 00002: val_loss improved from 0.07267 to 0.07088, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 148s - loss: 0.0688 - val_loss: 0.0709\n",
      "Epoch 4/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0668Epoch 00003: val_loss improved from 0.07088 to 0.07049, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 145s - loss: 0.0669 - val_loss: 0.0705\n",
      "Epoch 5/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0655Epoch 00004: val_loss improved from 0.07049 to 0.07017, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 147s - loss: 0.0657 - val_loss: 0.0702\n",
      "Epoch 6/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0641Epoch 00005: val_loss did not improve\n",
      "12990/12990 [==============================] - 147s - loss: 0.0642 - val_loss: 0.0703\n",
      "Epoch 7/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0627Epoch 00006: val_loss did not improve\n",
      "12990/12990 [==============================] - 143s - loss: 0.0628 - val_loss: 0.0708\n",
      "Epoch 8/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0610Epoch 00007: val_loss improved from 0.07017 to 0.06685, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 147s - loss: 0.0611 - val_loss: 0.0669\n",
      "Epoch 9/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0595Epoch 00008: val_loss improved from 0.06685 to 0.06587, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 148s - loss: 0.0595 - val_loss: 0.0659\n",
      "Epoch 10/10\n",
      "12960/12990 [============================>.] - ETA: 0s - loss: 0.0578Epoch 00009: val_loss improved from 0.06587 to 0.06382, saving model to 20200102_045950_model-weights.hdf5\n",
      "12990/12990 [==============================] - 147s - loss: 0.0578 - val_loss: 0.0638\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "#バッチサイズは40以下にしてください。\n",
    "batch_size = 40\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "filename = now.strftime('%Y%m%d_%H%M%S') \n",
    "\n",
    "train_data, validation_data = loadCSVData()\n",
    "sampled_train_data = random.sample(train_data, int(len(train_data)))\n",
    "sampled_validation_data = random.sample(validation_data, int(len(validation_data)))\n",
    "\n",
    "print('Training data:', len(train_data))\n",
    "print('Training label:', len(validation_data))\n",
    "\n",
    "#モデルの指定\n",
    "model = nvidia_model()\n",
    "#モデルの訓練と保存\n",
    "history_object = trainModelAndSave(model, sampled_train_data, \n",
    "                                   sampled_validation_data, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
